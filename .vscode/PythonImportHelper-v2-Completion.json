[
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "dill",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dill",
        "description": "dill",
        "detail": "dill",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "StringIO",
        "description": "StringIO",
        "detail": "StringIO",
        "documentation": {}
    },
    {
        "label": "pands",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pands",
        "description": "pands",
        "detail": "pands",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "absolute_import",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "Object",
        "importPath": "my_lib",
        "description": "my_lib",
        "isExtraImport": true,
        "detail": "my_lib",
        "documentation": {}
    },
    {
        "label": "Object2",
        "importPath": "my_lib",
        "description": "my_lib",
        "isExtraImport": true,
        "detail": "my_lib",
        "documentation": {}
    },
    {
        "label": "Object3",
        "importPath": "my_lib",
        "description": "my_lib",
        "isExtraImport": true,
        "detail": "my_lib",
        "documentation": {}
    },
    {
        "label": "lib1",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib2",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib3",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib4",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib5",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib6",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib7",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib8",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib9",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib10",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib11",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib12",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib13",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib14",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "lib15",
        "importPath": "third_party",
        "description": "third_party",
        "isExtraImport": true,
        "detail": "third_party",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "google.protobuf.descriptor_pb2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.protobuf.descriptor_pb2",
        "description": "google.protobuf.descriptor_pb2",
        "detail": "google.protobuf.descriptor_pb2",
        "documentation": {}
    },
    {
        "label": "Bar",
        "importPath": "source",
        "description": "source",
        "isExtraImport": true,
        "detail": "source",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "pairwise",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "islice",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "importlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib",
        "description": "importlib",
        "detail": "importlib",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "toml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "toml",
        "description": "toml",
        "detail": "toml",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "loguru",
        "description": "loguru",
        "isExtraImport": true,
        "detail": "loguru",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "patch",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "Mock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "MagicMock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "DynelConfig",
        "importPath": "src.dynel",
        "description": "src.dynel",
        "isExtraImport": true,
        "detail": "src.dynel",
        "documentation": {}
    },
    {
        "label": "configure_logging",
        "importPath": "src.dynel",
        "description": "src.dynel",
        "isExtraImport": true,
        "detail": "src.dynel",
        "documentation": {}
    },
    {
        "label": "parse_command_line_args",
        "importPath": "src.dynel",
        "description": "src.dynel",
        "isExtraImport": true,
        "detail": "src.dynel",
        "documentation": {}
    },
    {
        "label": "ContextLevel",
        "importPath": "src.dynel",
        "description": "src.dynel",
        "isExtraImport": true,
        "detail": "src.dynel",
        "documentation": {}
    },
    {
        "label": "handle_exception",
        "importPath": "src.dynel",
        "description": "src.dynel",
        "isExtraImport": true,
        "detail": "src.dynel",
        "documentation": {}
    },
    {
        "label": "module_exception_handler",
        "importPath": "src.dynel",
        "description": "src.dynel",
        "isExtraImport": true,
        "detail": "src.dynel",
        "documentation": {}
    },
    {
        "label": "run_command",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "description": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "peekOfCode": "def run_command(cmd):\n    \"\"\"\n    Execute a shell command and return its exit code, stdout, and stderr.\n    Args:\n        cmd: List of command arguments to execute\n    Returns:\n        Tuple containing (return_code, stdout, stderr)\n    \"\"\"\n    try:\n        process = subprocess.Popen(",
        "detail": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "documentation": {}
    },
    {
        "label": "update_cmd",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "description": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "peekOfCode": "update_cmd = [\"terraform-docs\", \".\"]\nreturn_code, stdout, stderr = run_command(update_cmd)\nif stderr:\n    print(f\"terraform-docs error: Warning during execution:\\n{stderr}\", file=sys.stderr)\n# Check git status for unstaged README changes\nstatus_cmd = [\"git\", \"status\", \"--porcelain\"]\nreturn_code, stdout, stderr = run_command(status_cmd)\n# Look for any README.md files in the unstaged changes\nunstaged_readmes = [\n    line.split()[-1]",
        "detail": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "documentation": {}
    },
    {
        "label": "status_cmd",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "description": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "peekOfCode": "status_cmd = [\"git\", \"status\", \"--porcelain\"]\nreturn_code, stdout, stderr = run_command(status_cmd)\n# Look for any README.md files in the unstaged changes\nunstaged_readmes = [\n    line.split()[-1]\n    for line in stdout.splitlines()\n    if line.startswith(\" M\") and line.endswith(\"README.md\")\n]\n# Check if we found any unstaged README files\nif len(unstaged_readmes) > 0:",
        "detail": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "documentation": {}
    },
    {
        "label": "unstaged_readmes",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "description": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "peekOfCode": "unstaged_readmes = [\n    line.split()[-1]\n    for line in stdout.splitlines()\n    if line.startswith(\" M\") and line.endswith(\"README.md\")\n]\n# Check if we found any unstaged README files\nif len(unstaged_readmes) > 0:\n    print(\"terraform-docs error: Please stage any README changes before committing.\")\n    sys.exit(1)\nprint(\"terraform-docs: Documentation is up to date\")",
        "detail": ".trunk.plugins.trunk.actions.terraform-docs.terraform-docs",
        "documentation": {}
    },
    {
        "label": "Example3",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "peekOfCode": "class Example3(   object ):\n    def __init__    ( self, bar ):\n     #Comments should have a space after the hash.\n     if bar : bar+=1;  bar=bar* bar   ; return bar\n     else:\n                    some_string = \"\"\"\n                       Indentation in multiline strings should not be touched.\nOnly actual code should be reindented.\n\"\"\"\n                    return (sys.path, some_string)",
        "detail": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "example1",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "peekOfCode": "def example1():\n    ####This is a long comment. This should be wrapped to fit within 72 characters.\n    some_tuple=(   1,2, 3,'a'  );\n    some_variable={'long':'Long code lines should be wrapped within 79 characters.',\n    'other':[math.pi, 100,200,300,9876543210,'This is a long string that goes on'],\n    'more':{'inner':'This whole logical line should be wrapped.',some_tuple:[1,\n    20,300,40000,500000000,60000000000000000]}}\n    return (some_tuple, some_variable)\ndef example2(): return {'has_key() is deprecated':True}.has_key({'f':2}.has_key(''));\nclass Example3(   object ):",
        "detail": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "example2",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "peekOfCode": "def example2(): return {'has_key() is deprecated':True}.has_key({'f':2}.has_key(''));\nclass Example3(   object ):\n    def __init__    ( self, bar ):\n     #Comments should have a space after the hash.\n     if bar : bar+=1;  bar=bar* bar   ; return bar\n     else:\n                    some_string = \"\"\"\n                       Indentation in multiline strings should not be touched.\nOnly actual code should be reindented.\n\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.autopep8.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "pick",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.bandit.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.bandit.test_data.basic.in",
        "peekOfCode": "pick = dill.dumps({\"a\": \"b\", \"c\": \"d\"})\nprint(dill.loads(pick))\nfile_obj = StringIO.StringIO()\ndill.dump([1, 2, \"3\"], file_obj)",
        "detail": ".trunk.plugins.trunk.linters.bandit.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "file_obj",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.bandit.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.bandit.test_data.basic.in",
        "peekOfCode": "file_obj = StringIO.StringIO()\ndill.dump([1, 2, \"3\"], file_obj)",
        "detail": ".trunk.plugins.trunk.linters.bandit.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "NoDocstring",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "peekOfCode": "class NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1\nclass Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'\n    def __inti__(self):\n        prit(\"this is not a valid method\")\n        callbak = lamda x: x * 2\n    varName1 = \"helol ym anme is var\"",
        "detail": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "Globe",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "peekOfCode": "class Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'\n    def __inti__(self):\n        prit(\"this is not a valid method\")\n        callbak = lamda x: x * 2\n    varName1 = \"helol ym anme is var\"\ncachedir = \"/tmp\"",
        "detail": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "peekOfCode": "def main():\n    try:\n        pass\n    except (Exception, TypeError):\n        pass\nimport sys\nimport pands\nclass NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1",
        "detail": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "cachedir",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "peekOfCode": "cachedir = \"/tmp\"",
        "detail": ".trunk.plugins.trunk.linters.codespell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.codespell.codespell_to_sarif",
        "description": ".trunk.plugins.trunk.linters.codespell.codespell_to_sarif",
        "peekOfCode": "def to_result_sarif(\n    path: str, line_number: int, column_number: int, rule_id: str, message: str\n):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.codespell.codespell_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.codespell.codespell_to_sarif",
        "description": ".trunk.plugins.trunk.linters.codespell.codespell_to_sarif",
        "peekOfCode": "def main(argv):\n    results = []\n    for line in sys.stdin.readlines():\n        filename, line_number, message = line.split(\":\")\n        results.append(\n            to_result_sarif(\n                filename, int(line_number), 0, \"misspelled\", message.strip()\n            )\n        )\n    sarif = {",
        "detail": ".trunk.plugins.trunk.linters.codespell.codespell_to_sarif",
        "documentation": {}
    },
    {
        "label": "NoDocstring",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "peekOfCode": "class NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1\nclass Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'\n    def __inti__(self):\n        prit(\"this is not a valid method\")\n        callbak = lamda x: x * 2\n    varName1 = \"helol ym anme is var\"",
        "detail": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "Globe",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "peekOfCode": "class Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'\n    def __inti__(self):\n        prit(\"this is not a valid method\")\n        callbak = lamda x: x * 2\n    varName1 = \"helol ym anme is var\"\ncachedir = \"/tmp\"",
        "detail": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "peekOfCode": "def main():\n    try:\n        pass\n    except (Exception, TypeError):\n        pass\nimport sys\nimport pands\nclass NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1",
        "detail": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "cachedir",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "description": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "peekOfCode": "cachedir = \"/tmp\"",
        "detail": ".trunk.plugins.trunk.linters.cspell.test_data.basic_py.in",
        "documentation": {}
    },
    {
        "label": "NoDocstring",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "peekOfCode": "class NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1\nclass Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'",
        "detail": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "Globe",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "peekOfCode": "class Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'",
        "detail": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "peekOfCode": "def main():\n    try:\n        pass\n    except (Exception, TypeError):\n        pass\nimport sys\n# trunk-ignore(flake8/F401): this will trigger a warning to verify that the config is applied\nclass NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1",
        "detail": ".trunk.plugins.trunk.linters.flake8.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "aws_access_key_id",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "peekOfCode": "aws_access_key_id = \"AKIAIO5FODNN7EXAMPLE\"\naws_token = \"AKIALALEMEL33243OLIA\"\nprivate_key = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\nQyNTUxOQAAACA8YWKYztuuvxUIMomc3zv0OdXCT57Cc2cRYu3TMbX9XAAAAJDiKO3C4ijt\nwgAAAAtzc2gtZWQyNTUxOQAAACA8YWKYztuuvxUIMomc3zv0OdXCT57Cc2cRYu3TMbX9XA\nAAAECzmj8DGxg5YHtBK4AmBttMXDQHsPAaCyYHQjJ4YujRBTxhYpjO266/FQgyiZzfO/Q5\n1cJPnsJzZxFi7dMxtf1cAAAADHJvb3RAZGV2aG9zdAE=\n-----END OPENSSH PRIVATE KEY-----\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "documentation": {}
    },
    {
        "label": "aws_token",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "peekOfCode": "aws_token = \"AKIALALEMEL33243OLIA\"\nprivate_key = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\nQyNTUxOQAAACA8YWKYztuuvxUIMomc3zv0OdXCT57Cc2cRYu3TMbX9XAAAAJDiKO3C4ijt\nwgAAAAtzc2gtZWQyNTUxOQAAACA8YWKYztuuvxUIMomc3zv0OdXCT57Cc2cRYu3TMbX9XA\nAAAECzmj8DGxg5YHtBK4AmBttMXDQHsPAaCyYHQjJ4YujRBTxhYpjO266/FQgyiZzfO/Q5\n1cJPnsJzZxFi7dMxtf1cAAAADHJvb3RAZGV2aG9zdAE=\n-----END OPENSSH PRIVATE KEY-----\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "documentation": {}
    },
    {
        "label": "private_key",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "peekOfCode": "private_key = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\nQyNTUxOQAAACA8YWKYztuuvxUIMomc3zv0OdXCT57Cc2cRYu3TMbX9XAAAAJDiKO3C4ijt\nwgAAAAtzc2gtZWQyNTUxOQAAACA8YWKYztuuvxUIMomc3zv0OdXCT57Cc2cRYu3TMbX9XA\nAAAECzmj8DGxg5YHtBK4AmBttMXDQHsPAaCyYHQjJ4YujRBTxhYpjO266/FQgyiZzfO/Q5\n1cJPnsJzZxFi7dMxtf1cAAAADHJvb3RAZGV2aG9zdAE=\n-----END OPENSSH PRIVATE KEY-----\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.gitleaks.test_data.basic",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.graphql-schema-linter.parse",
        "description": ".trunk.plugins.trunk.linters.graphql-schema-linter.parse",
        "peekOfCode": "def to_result_sarif(path: str, lineno: int, colno: int, rule_id: str, message: str):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,\n                    },\n                    \"region\": {",
        "detail": ".trunk.plugins.trunk.linters.graphql-schema-linter.parse",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.graphql-schema-linter.parse",
        "description": ".trunk.plugins.trunk.linters.graphql-schema-linter.parse",
        "peekOfCode": "def main(argv):\n    output_json = json.load(sys.stdin)\n    errors = output_json.get(\"errors\", [])\n    results = []\n    for error in errors:\n        rule = error.get(\"rule\", \"\")\n        message = error.get(\"message\", \"\")\n        location = error.get(\"location\")\n        if location:\n            path = location.get(\"file\", \"\")",
        "detail": ".trunk.plugins.trunk.linters.graphql-schema-linter.parse",
        "documentation": {}
    },
    {
        "label": "try_find_string_in_file",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "description": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "peekOfCode": "def try_find_string_in_file(filename, search_string):\n    with open(filename, \"r\") as f:\n        for i, line in enumerate(f):\n            index = line.find(search_string)\n            if index != -1:\n                return i + 1, index + 1\n    return 0, 0\ndef to_result_sarif(\n    path: str, line_number: int, column_number: int, rule_id: str, message: str\n):",
        "detail": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "description": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "peekOfCode": "def to_result_sarif(\n    path: str, line_number: int, column_number: int, rule_id: str, message: str\n):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "description": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "peekOfCode": "def main(argv):\n    parser = argparse.ArgumentParser(description=\"Parse output of markdown-link-check\")\n    parser.add_argument(\"--target\", dest=\"target\")\n    args = parser.parse_args()\n    results = []\n    # Line numbers are not reported out of the tool right now - so we regex parse the output to extract issue codes\n    for line in sys.stdin:\n        parse_reg = \"\\s*(\\[.*\\])\\s(.*)â†’.*Status:\\s*(\\d*)(.*)\"\n        filename = args.target\n        parse_result = re.fullmatch(parse_reg, line, flags=re.DOTALL)",
        "detail": ".trunk.plugins.trunk.linters.markdown-link-check.parse",
        "documentation": {}
    },
    {
        "label": "greeting",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "peekOfCode": "def greeting(name: str) -> str:\n    return \"Hello \" + name\ndef printer() -> None:\n    print(\"Hello\")\ngreeting(3)\ngreeting(b\"Alice\")\na = printer()\nc: str = 4\nfrom source import Bar\ndef bad_foo(bar: Bar) -> str:",
        "detail": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "documentation": {}
    },
    {
        "label": "printer",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "peekOfCode": "def printer() -> None:\n    print(\"Hello\")\ngreeting(3)\ngreeting(b\"Alice\")\na = printer()\nc: str = 4\nfrom source import Bar\ndef bad_foo(bar: Bar) -> str:\n  return bar.a + bar.b",
        "detail": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "documentation": {}
    },
    {
        "label": "bad_foo",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "peekOfCode": "def bad_foo(bar: Bar) -> str:\n  return bar.a + bar.b",
        "detail": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "description": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "peekOfCode": "a = printer()\nc: str = 4\nfrom source import Bar\ndef bad_foo(bar: Bar) -> str:\n  return bar.a + bar.b",
        "detail": ".trunk.plugins.trunk.linters.mypy.test_data.basic",
        "documentation": {}
    },
    {
        "label": "Bar",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.mypy.test_data.source",
        "description": ".trunk.plugins.trunk.linters.mypy.test_data.source",
        "peekOfCode": "class Bar:\n  a: int\n  b: int\ndef bad_function() -> int:\n  print(\"returns nothing\")",
        "detail": ".trunk.plugins.trunk.linters.mypy.test_data.source",
        "documentation": {}
    },
    {
        "label": "bad_function",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.mypy.test_data.source",
        "description": ".trunk.plugins.trunk.linters.mypy.test_data.source",
        "peekOfCode": "def bad_function() -> int:\n  print(\"returns nothing\")",
        "detail": ".trunk.plugins.trunk.linters.mypy.test_data.source",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.nancy.parse",
        "description": ".trunk.plugins.trunk.linters.nancy.parse",
        "peekOfCode": "def to_result_sarif(\n    path: str, line_number: int, column_number: int, rule_id: str, message: str\n):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.nancy.parse",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.nancy.parse",
        "description": ".trunk.plugins.trunk.linters.nancy.parse",
        "peekOfCode": "def main(argv):\n    results = []\n    nancy_output = json.load(sys.stdin)\n    for vuln_entry in nancy_output.get(\"vulnerable\", []):\n        for vuln in vuln_entry.get(\"Vulnerabilities\", []):\n            results.append(\n                to_result_sarif(\n                    \".\",\n                    0,\n                    0,",
        "detail": ".trunk.plugins.trunk.linters.nancy.parse",
        "documentation": {}
    },
    {
        "label": "get_sarif_severity",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "def get_sarif_severity(vuln) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"\n    if \"database_specific\" not in vuln:\n        return DEFAULT_SARIF_SEVERITY\n    vuln_metadata = vuln[\"database_specific\"]\n    if \"severity\" not in vuln_metadata:\n        return DEFAULT_SARIF_SEVERITY\n    severity = vuln_metadata[\"severity\"].upper()\n    return SARIF_SEVERITY_BY_OSV_SEVERITY.get(severity, DEFAULT_SARIF_SEVERITY)\ndef to_result_sarif(",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "def to_result_sarif(\n    path: str, lineno: int, vuln_id: str, description: str, severity: str\n):\n    return {\n        \"level\": severity,\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "join_common_sets",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "def join_common_sets(lst):\n    init_len = 0\n    final_len = 1\n    while init_len != final_len:\n        init_len = len(lst)\n        ret = []\n        for s in lst:\n            unique = True\n            for stored_set in ret:\n                if len(stored_set.intersection(s)) > 0:",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "get_preferred_alias",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "def get_preferred_alias(aliases):\n    for rx in PREFERRED_ORDER:\n        found_aliases = sorted(alias for alias in aliases if re.match(rx, alias))\n        if len(found_aliases) > 0:\n            return found_aliases[0]\n    return sorted(aliases)[0]\ndef main(argv):\n    try:\n        # On Windows, Unicode characters in the osv-scanner output cause json parsing errors. Filter them out since we don't care about their fields.\n        if sys.platform == \"win32\":",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "def main(argv):\n    try:\n        # On Windows, Unicode characters in the osv-scanner output cause json parsing errors. Filter them out since we don't care about their fields.\n        if sys.platform == \"win32\":\n            filtered_stdin = \"\".join(i for i in sys.stdin.read() if ord(i) < 256)\n            osv_json = json.loads(filtered_stdin)\n        else:\n            osv_json = json.load(sys.stdin)\n    except json.decoder.JSONDecodeError as err:\n        if str(err) == \"Expecting value: line 1 column 1 (char 0)\":",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "SARIF_SEVERITY_BY_OSV_SEVERITY",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "SARIF_SEVERITY_BY_OSV_SEVERITY = {\n    \"CRITICAL\": \"error\",\n    \"HIGH\": \"error\",\n    \"MODERATE\": \"warning\",\n    \"MEDIUM\": \"warning\",\n    \"LOW\": \"note\",\n}\nDEFAULT_SARIF_SEVERITY = \"error\"\ndef get_sarif_severity(vuln) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SARIF_SEVERITY",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "DEFAULT_SARIF_SEVERITY = \"error\"\ndef get_sarif_severity(vuln) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"\n    if \"database_specific\" not in vuln:\n        return DEFAULT_SARIF_SEVERITY\n    vuln_metadata = vuln[\"database_specific\"]\n    if \"severity\" not in vuln_metadata:\n        return DEFAULT_SARIF_SEVERITY\n    severity = vuln_metadata[\"severity\"].upper()\n    return SARIF_SEVERITY_BY_OSV_SEVERITY.get(severity, DEFAULT_SARIF_SEVERITY)",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "PREFERRED_ORDER",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "description": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "peekOfCode": "PREFERRED_ORDER = [\"GHSA-.*\", \"CVE-.*\", \"PYSEC-.*\"]\ndef get_preferred_alias(aliases):\n    for rx in PREFERRED_ORDER:\n        found_aliases = sorted(alias for alias in aliases if re.match(rx, alias))\n        if len(found_aliases) > 0:\n            return found_aliases[0]\n    return sorted(aliases)[0]\ndef main(argv):\n    try:\n        # On Windows, Unicode characters in the osv-scanner output cause json parsing errors. Filter them out since we don't care about their fields.",
        "detail": ".trunk.plugins.trunk.linters.osv-scanner.osv_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.phpstan.phpstan_parser",
        "description": ".trunk.plugins.trunk.linters.phpstan.phpstan_parser",
        "peekOfCode": "def main():\n    phpstan_json = json.loads(sys.stdin.read())\n    results = []\n    for file_name in phpstan_json[\"files\"]:\n        file_result = phpstan_json[\"files\"][file_name]\n        for result in file_result[\"messages\"]:\n            result = {\n                # We do not have a ruleId\n                \"message\": {\n                    \"text\": result[\"message\"],",
        "detail": ".trunk.plugins.trunk.linters.phpstan.phpstan_parser",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.prettier.prettier_to_sarif",
        "description": ".trunk.plugins.trunk.linters.prettier.prettier_to_sarif",
        "peekOfCode": "def to_result_sarif(path: str, description: str, line: int = 0, column: int = 0):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,\n                    },\n                    \"region\": {",
        "detail": ".trunk.plugins.trunk.linters.prettier.prettier_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.prettier.prettier_to_sarif",
        "description": ".trunk.plugins.trunk.linters.prettier.prettier_to_sarif",
        "peekOfCode": "def main(argv):\n    if len(argv) < 2:\n        print(\"Usage: trivy_to_sarif.py <exit_code>)\")\n        sys.exit(1)\n    if argv[1] == \"0\":\n        results = []\n        sarif = {\n            \"$schema\": \"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json\",\n            \"version\": \"2.1.0\",\n            \"runs\": [{\"results\": results}],",
        "detail": ".trunk.plugins.trunk.linters.prettier.prettier_to_sarif",
        "documentation": {}
    },
    {
        "label": "shift",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "peekOfCode": "shift = 3\nchoice = raw_input(\"would you like to encode or decode?\")\nword = raw_input(\"Please enter text\")\nletters = string.ascii_letters + string.punctuation + string.digits\nencoded = \"\"",
        "detail": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "choice",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "peekOfCode": "choice = raw_input(\"would you like to encode or decode?\")\nword = raw_input(\"Please enter text\")\nletters = string.ascii_letters + string.punctuation + string.digits\nencoded = \"\"",
        "detail": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "word",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "peekOfCode": "word = raw_input(\"Please enter text\")\nletters = string.ascii_letters + string.punctuation + string.digits\nencoded = \"\"",
        "detail": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "letters",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "peekOfCode": "letters = string.ascii_letters + string.punctuation + string.digits\nencoded = \"\"",
        "detail": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "encoded",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "peekOfCode": "encoded = \"\"",
        "detail": ".trunk.plugins.trunk.linters.pylint.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "foo",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.pylint.test_data.severity",
        "description": ".trunk.plugins.trunk.linters.pylint.test_data.severity",
        "peekOfCode": "def foo():\n    return \"bar\"",
        "detail": ".trunk.plugins.trunk.linters.pylint.test_data.severity",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "class A:\n    def method1(self) -> None:\n        self.x = 1\n    def method2(self) -> None:\n        self.x = \"\" # Mypy treats this as an error because `x` is implicitly declared as `int`\na = A()\nreveal_type(a.x)\na.x = \"\" # Pyright allows this because the type of `x` is `int | str`\na.x = 3.0 # Pyright treats this as an error because the type of `x` is `int | str`\nclass A:",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "class A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)\nprint(A.y)\nprint(A.z) # pyright shows error, mypy shows no error\nclass Color(Enum):\n    RED = 1",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "Color",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "class Color(Enum):\n    RED = 1\n    BLUE = 2\ndef is_red(color: Color) -> bool:\n    if color == Color.RED:\n        return True\n    elif color == Color.BLUE:\n        return False\n    # mypy reports error: Missing return statement\ndef func(val: int | None):",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "wrong_type",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "def wrong_type(x: int) -> str:\n    return x  # error: Incompatible return value type (got \"int\", expected \"str\")\nclass A:\n    def method1(self) -> None:\n        self.x = 1\n    def method2(self) -> None:\n        self.x = \"\" # Mypy treats this as an error because `x` is implicitly declared as `int`\na = A()\nreveal_type(a.x)\na.x = \"\" # Pyright allows this because the type of `x` is `int | str`",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "is_red",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "def is_red(color: Color) -> bool:\n    if color == Color.RED:\n        return True\n    elif color == Color.BLUE:\n        return False\n    # mypy reports error: Missing return statement\ndef func(val: int | None):\n    if val is not None:\n        def inner_1() -> None:\n            reveal_type(val)",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "func",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "def func(val: int | None):\n    if val is not None:\n        def inner_1() -> None:\n            reveal_type(val)\n            print(val + 1)  # mypy produces a false positive error here\n        inner_2 = lambda: reveal_type(val) + 1\n        inner_1()\n        inner_2()",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "a = A()\nreveal_type(a.x)\na.x = \"\" # Pyright allows this because the type of `x` is `int | str`\na.x = 3.0 # Pyright treats this as an error because the type of `x` is `int | str`\nclass A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "a.x",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "a.x = \"\" # Pyright allows this because the type of `x` is `int | str`\na.x = 3.0 # Pyright treats this as an error because the type of `x` is `int | str`\nclass A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)\nprint(A.y)\nprint(A.z) # pyright shows error, mypy shows no error",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "a.x",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "peekOfCode": "a.x = 3.0 # Pyright treats this as an error because the type of `x` is `int | str`\nclass A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)\nprint(A.y)\nprint(A.z) # pyright shows error, mypy shows no error\nclass Color(Enum):",
        "detail": ".trunk.plugins.trunk.linters.pyright.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pyright.pyright_to_sarif",
        "description": ".trunk.plugins.trunk.linters.pyright.pyright_to_sarif",
        "peekOfCode": "results = []\nfor result in json.load(sys.stdin)[\"generalDiagnostics\"]:\n    parse = {\n        \"level\": result[\"severity\"] if result[\"severity\"] != \"information\" else \"note\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": result[\"file\"],\n                    },",
        "detail": ".trunk.plugins.trunk.linters.pyright.pyright_to_sarif",
        "documentation": {}
    },
    {
        "label": "sarif",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.pyright.pyright_to_sarif",
        "description": ".trunk.plugins.trunk.linters.pyright.pyright_to_sarif",
        "peekOfCode": "sarif = {\n    \"$schema\": \"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json\",\n    \"version\": \"2.1.0\",\n    \"runs\": [{\"results\": results}],\n}\nprint(json.dumps(sarif, indent=2))",
        "detail": ".trunk.plugins.trunk.linters.pyright.pyright_to_sarif",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.remark-lint.parse",
        "description": ".trunk.plugins.trunk.linters.remark-lint.parse",
        "peekOfCode": "def to_result_sarif(\n    path: str, line_number: int, column_number: int, rule_id: str, message: str\n):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.remark-lint.parse",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.remark-lint.parse",
        "description": ".trunk.plugins.trunk.linters.remark-lint.parse",
        "peekOfCode": "def main(argv):\n    results = []\n    content_json = sys.stdin.read()\n    content = json.loads(content_json)\n    for file_content in content:\n        messages = file_content.get(\"messages\", [])\n        if messages:\n            for msg in messages:\n                results.append(\n                    to_result_sarif(",
        "detail": ".trunk.plugins.trunk.linters.remark-lint.parse",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.renovate.parse",
        "description": ".trunk.plugins.trunk.linters.renovate.parse",
        "peekOfCode": "def to_result_sarif(\n    path: str, line_number: int, column_number: int, rule_id: str, message: str\n):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.renovate.parse",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.renovate.parse",
        "description": ".trunk.plugins.trunk.linters.renovate.parse",
        "peekOfCode": "def main(argv):\n    results = []\n    content = sys.stdin.read()\n    parse_reg = \"(.*WARN:.*could not be parsed)(.*)\"\n    error_section = content.find('\"errors\": [')\n    parse_result = re.fullmatch(parse_reg, content, flags=re.DOTALL)\n    if parse_result:\n        warn_section = parse_result.group(2)\n        json_content = \"{\" + warn_section + \"}\"\n        error_output = json.loads(json_content)",
        "detail": ".trunk.plugins.trunk.linters.renovate.parse",
        "documentation": {}
    },
    {
        "label": "map_severity",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "description": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "peekOfCode": "def map_severity(severity):\n    if severity in [\"convention\", \"refactor\", \"info\"]:\n        return \"note\"\n    if severity in [\"warning\"]:\n        return \"warning\"\n    if severity in [\"error\", \"fatal\"]:\n        return \"error\"\n    return \"none\"\nresults = []\nfor file in json.load(sys.stdin)[\"files\"]:",
        "detail": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "description": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "peekOfCode": "results = []\nfor file in json.load(sys.stdin)[\"files\"]:\n    for offense in file[\"offenses\"]:\n        parse = {\n            \"level\": map_severity(offense[\"severity\"]),\n            \"locations\": [\n                {\n                    \"physicalLocation\": {\n                        \"artifactLocation\": {\n                            \"uri\": file[\"path\"],",
        "detail": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "documentation": {}
    },
    {
        "label": "sarif",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "description": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "peekOfCode": "sarif = {\n    \"$schema\": \"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json\",\n    \"version\": \"2.1.0\",\n    \"runs\": [{\"results\": results}],\n}\nprint(json.dumps(sarif, indent=2))",
        "detail": ".trunk.plugins.trunk.linters.rubocop.rubocop_to_sarif",
        "documentation": {}
    },
    {
        "label": "NoDocstring",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "peekOfCode": "class NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1\nclass Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'",
        "detail": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "Globe",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "peekOfCode": "class Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'",
        "detail": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "peekOfCode": "def main():\n    try:\n        pass\n    except (Exception, TypeError):\n        pass\n# trunk-ignore(ruff/F401)\nimport json\nimport sys\nclass NoDocstring(object):\n    def __init__(self, arg1):",
        "detail": ".trunk.plugins.trunk.linters.ruff.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "f",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.ruff.test_data.syntax.in",
        "description": ".trunk.plugins.trunk.linters.ruff.test_data.syntax.in",
        "peekOfCode": "def f(): {",
        "detail": ".trunk.plugins.trunk.linters.ruff.test_data.syntax.in",
        "documentation": {}
    },
    {
        "label": "get_region",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "description": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "peekOfCode": "def get_region(entry, column_offset=0):\n    location = entry[\"location\"]\n    region = {\n        \"startColumn\": location[\"column\"] + column_offset,\n        \"startLine\": location[\"row\"],\n    }\n    if \"end_location\" in entry:\n        end_location = entry[\"end_location\"]\n        region[\"endColumn\"] = end_location[\"column\"] + column_offset\n        region[\"endLine\"] = end_location[\"row\"]",
        "detail": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "description": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "peekOfCode": "results = []\ndef get_region(entry, column_offset=0):\n    location = entry[\"location\"]\n    region = {\n        \"startColumn\": location[\"column\"] + column_offset,\n        \"startLine\": location[\"row\"],\n    }\n    if \"end_location\" in entry:\n        end_location = entry[\"end_location\"]\n        region[\"endColumn\"] = end_location[\"column\"] + column_offset",
        "detail": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "documentation": {}
    },
    {
        "label": "ruff_column_index",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "description": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "peekOfCode": "ruff_column_index = 1\nif len(sys.argv) > 1:\n    ruff_column_index = int(sys.argv[1])\nfor result in json.load(sys.stdin):\n    # As of ruff v0.0.260, some autofixable diagnostics may appear redundantly\n    if \"location\" not in result:\n        continue\n    filepath = result[\"filename\"]\n    # Ruff will set code to null for syntax errors\n    rule_id = result[\"code\"] or \"E999\"",
        "detail": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "documentation": {}
    },
    {
        "label": "sarif",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "description": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "peekOfCode": "sarif = {\n    \"$schema\": \"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json\",\n    \"version\": \"2.1.0\",\n    \"runs\": [{\"results\": results}],\n}\nprint(json.dumps(sarif, indent=2))",
        "detail": ".trunk.plugins.trunk.linters.ruff.ruff_to_sarif",
        "documentation": {}
    },
    {
        "label": "unvalidated_value",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.semgrep.test_data.request",
        "description": ".trunk.plugins.trunk.linters.semgrep.test_data.request",
        "peekOfCode": "def unvalidated_value(request):\n    value = request.GET.get('something')\n    function = globals().get(value)\n    if function:\n        return function(request)",
        "detail": ".trunk.plugins.trunk.linters.semgrep.test_data.request",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.sourcery.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.sourcery.test_data.basic.in",
        "peekOfCode": "def test():\n  substitution = \"hello %s\" % test\n  my_list = List()\n  try:\n    pass\n  except Exception:\n    raise Exception(\"test\")",
        "detail": ".trunk.plugins.trunk.linters.sourcery.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.sourcery.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.sourcery.test_data.basic.in",
        "peekOfCode": "test = \"world\"\ndef test():\n  substitution = \"hello %s\" % test\n  my_list = List()\n  try:\n    pass\n  except Exception:\n    raise Exception(\"test\")",
        "detail": ".trunk.plugins.trunk.linters.sourcery.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.sqlfluff.sqlfluff_to_sarif",
        "description": ".trunk.plugins.trunk.linters.sqlfluff.sqlfluff_to_sarif",
        "peekOfCode": "def to_result_sarif(\n    path: str,\n    start_line_number: int,\n    start_column_number: int,\n    end_line_number: Optional[int],\n    end_column_number: Optional[int],\n    rule_id: str,\n    message: str,\n):\n    region = {",
        "detail": ".trunk.plugins.trunk.linters.sqlfluff.sqlfluff_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.sqlfluff.sqlfluff_to_sarif",
        "description": ".trunk.plugins.trunk.linters.sqlfluff.sqlfluff_to_sarif",
        "peekOfCode": "def main(argv):\n    sqlfluff_json = json.load(sys.stdin)\n    results = []\n    for result in sqlfluff_json:\n        filepath = result[\"filepath\"]\n        for violation in result[\"violations\"]:\n            # In sqlfluff 3.0.0, line_no/line_pos replaced with start_*/end_*\n            start_line_number = violation.get(\"start_line_no\", violation.get(\"line_no\"))\n            start_column_number = violation.get(\n                \"start_line_pos\", violation.get(\"line_pos\")",
        "detail": ".trunk.plugins.trunk.linters.sqlfluff.sqlfluff_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.terrascan.sarif_to_sarif",
        "description": ".trunk.plugins.trunk.linters.terrascan.sarif_to_sarif",
        "peekOfCode": "def main(argv):\n    input_sarif = json.load(sys.stdin)\n    # strip \"file:\" from the beginning of each value in the 'file' field in the 'location' object in sarif format\n    for run in input_sarif[\"runs\"]:\n        for result in run[\"results\"]:\n            for location in result[\"locations\"]:\n                location[\"physicalLocation\"][\"artifactLocation\"][\"uri\"] = location[\n                    \"physicalLocation\"\n                ][\"artifactLocation\"][\"uri\"][5:]\n    print(json.dumps(input_sarif, indent=2))",
        "detail": ".trunk.plugins.trunk.linters.terrascan.sarif_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.tfsec.parse",
        "description": ".trunk.plugins.trunk.linters.tfsec.parse",
        "peekOfCode": "def main():\n    original_input = sys.stdin.read()\n    try:\n        index = original_input.index(\"{\")\n        print(original_input[index:])\n    except ValueError:\n        print(original_input)\nif __name__ == \"__main__\":\n    main()",
        "detail": ".trunk.plugins.trunk.linters.tfsec.parse",
        "documentation": {}
    },
    {
        "label": "aws_access_key_id",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "description": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "peekOfCode": "aws_access_key_id = \"AKIAXYZDQCEN4EXAMPLE\"\naws_secret_access_key = \"Tg0pz8Jii8hkLx4+PnUisM8GmKs3a2DK+EXAMPLE\"\n# The below keys are copied from https://github.com/dustin-decker/secretsandstuff\ngithub_secret = \"369963c1434c377428ca8531fbc46c0c43d037a0\"\nbasic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = \"\"\"\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu",
        "detail": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "documentation": {}
    },
    {
        "label": "aws_secret_access_key",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "description": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "peekOfCode": "aws_secret_access_key = \"Tg0pz8Jii8hkLx4+PnUisM8GmKs3a2DK+EXAMPLE\"\n# The below keys are copied from https://github.com/dustin-decker/secretsandstuff\ngithub_secret = \"369963c1434c377428ca8531fbc46c0c43d037a0\"\nbasic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = \"\"\"\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF",
        "detail": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "documentation": {}
    },
    {
        "label": "github_secret",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "description": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "peekOfCode": "github_secret = \"369963c1434c377428ca8531fbc46c0c43d037a0\"\nbasic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = \"\"\"\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF\nOLZKbDA5aa24idpcD8b1I9/RzTOB1fu0of5xd9vgODzGw5JvHQSJ0FaA42aNBMGwrDhDB3\nsgnRNdWf6NNIh8KpXXMKJADf3klsyn6He8L2bPMp8a4wwys2YB35p5zQ0JURovsdewlOxH",
        "detail": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "documentation": {}
    },
    {
        "label": "basic_auth",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "description": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "peekOfCode": "basic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = \"\"\"\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF\nOLZKbDA5aa24idpcD8b1I9/RzTOB1fu0of5xd9vgODzGw5JvHQSJ0FaA42aNBMGwrDhDB3\nsgnRNdWf6NNIh8KpXXMKJADf3klsyn6He8L2bPMp8a4wwys2YB35p5zQ0JURovsdewlOxH\nNT7eP19eVf4dCreibxUmRUaob5DEoHEk8WrxjKWIYUuLeD6AfcW6oXyRU2Yy8Vrt6SqFl5",
        "detail": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "documentation": {}
    },
    {
        "label": "priv_key",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "description": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "peekOfCode": "priv_key = \"\"\"\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF\nOLZKbDA5aa24idpcD8b1I9/RzTOB1fu0of5xd9vgODzGw5JvHQSJ0FaA42aNBMGwrDhDB3\nsgnRNdWf6NNIh8KpXXMKJADf3klsyn6He8L2bPMp8a4wwys2YB35p5zQ0JURovsdewlOxH\nNT7eP19eVf4dCreibxUmRUaob5DEoHEk8WrxjKWIYUuLeD6AfcW6oXyRU2Yy8Vrt6SqFl5\nWAi47VMFTkDZYS/eCvG53q9UBHpCj7Qvb0vSkCZXBvBIhlw193F3PX4WvO1IXsMwvQ1D1X",
        "detail": ".trunk.plugins.trunk.linters.trivy.test_data.secrets",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_config_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_config_to_sarif",
        "peekOfCode": "def to_result_sarif(path: str, vuln_id: str, description: str, line: int = 0):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,\n                    },\n                    \"region\": {",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_config_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_config_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_config_to_sarif",
        "peekOfCode": "def main(argv):\n    trivy_json = json.load(sys.stdin)\n    path = trivy_json[\"ArtifactName\"]\n    results = []\n    for result in trivy_json.get(\"Results\", []):\n        if \"Misconfigurations\" not in result:\n            continue\n        for vuln in result[\"Misconfigurations\"]:\n            vuln_id = vuln[\"ID\"]\n            message = vuln[\"Message\"]",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_config_to_sarif",
        "documentation": {}
    },
    {
        "label": "get_sarif_severity",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "peekOfCode": "def get_sarif_severity(secret) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"\n    if \"Severity\" not in secret:\n        return DEFAULT_SARIF_SEVERITY\n    severity = secret[\"Severity\"].upper()\n    return SARIF_SEVERITY_BY_OSV_SEVERITY.get(severity, DEFAULT_SARIF_SEVERITY)\ndef to_result_sarif(path: str, severity: str, code: str, description: str, lineno: int):\n    return {\n        \"level\": severity,\n        \"locations\": [",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "peekOfCode": "def to_result_sarif(path: str, severity: str, code: str, description: str, lineno: int):\n    return {\n        \"level\": severity,\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,\n                    },\n                    \"region\": {",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "peekOfCode": "def main(argv):\n    trivy_json = json.load(sys.stdin)\n    results = []\n    for result in trivy_json.get(\"Results\", []):\n        path = trivy_json[\"ArtifactName\"]\n        for secret in result.get(\"Secrets\", []):\n            code = secret[\"RuleID\"]\n            description = secret[\"Title\"]\n            lineno = secret.get(\"StartLine\", 0)\n            results.append(",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "documentation": {}
    },
    {
        "label": "SARIF_SEVERITY_BY_OSV_SEVERITY",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "peekOfCode": "SARIF_SEVERITY_BY_OSV_SEVERITY = {\n    \"CRITICAL\": \"error\",\n    \"HIGH\": \"error\",\n    \"MODERATE\": \"warning\",\n    \"MEDIUM\": \"warning\",\n    \"LOW\": \"note\",\n}\nDEFAULT_SARIF_SEVERITY = \"error\"\ndef get_sarif_severity(secret) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SARIF_SEVERITY",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "peekOfCode": "DEFAULT_SARIF_SEVERITY = \"error\"\ndef get_sarif_severity(secret) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"\n    if \"Severity\" not in secret:\n        return DEFAULT_SARIF_SEVERITY\n    severity = secret[\"Severity\"].upper()\n    return SARIF_SEVERITY_BY_OSV_SEVERITY.get(severity, DEFAULT_SARIF_SEVERITY)\ndef to_result_sarif(path: str, severity: str, code: str, description: str, lineno: int):\n    return {\n        \"level\": severity,",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_secret_to_sarif",
        "documentation": {}
    },
    {
        "label": "get_sarif_severity",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "peekOfCode": "def get_sarif_severity(vuln) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"\n    if \"Severity\" not in vuln:\n        return DEFAULT_SARIF_SEVERITY\n    severity = vuln[\"Severity\"].upper()\n    return SARIF_SEVERITY_BY_OSV_SEVERITY.get(severity, DEFAULT_SARIF_SEVERITY)\ndef to_result_sarif(\n    path: str, severity: str, vuln_id: str, description: str, lineno: int\n):\n    return {",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "peekOfCode": "def to_result_sarif(\n    path: str, severity: str, vuln_id: str, description: str, lineno: int\n):\n    return {\n        \"level\": severity,\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "peekOfCode": "def main(argv):\n    trivy_json = json.load(sys.stdin)\n    results = []\n    lockfiles = {}\n    for result in trivy_json.get(\"Results\", []):\n        for vuln in result.get(\"Vulnerabilities\", []):\n            pkg_name = vuln[\"PkgName\"]\n            path = trivy_json[\"ArtifactName\"]\n            vuln_id = vuln[\"VulnerabilityID\"]\n            description = vuln[\"Title\"]",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "documentation": {}
    },
    {
        "label": "SARIF_SEVERITY_BY_OSV_SEVERITY",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "peekOfCode": "SARIF_SEVERITY_BY_OSV_SEVERITY = {\n    \"CRITICAL\": \"error\",\n    \"HIGH\": \"error\",\n    \"MODERATE\": \"warning\",\n    \"MEDIUM\": \"warning\",\n    \"LOW\": \"note\",\n}\nDEFAULT_SARIF_SEVERITY = \"error\"\ndef get_sarif_severity(vuln) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SARIF_SEVERITY",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "peekOfCode": "DEFAULT_SARIF_SEVERITY = \"error\"\ndef get_sarif_severity(vuln) -> str:\n    \"\"\"Get the SARIF severity appropriate for a given OSV vulnerability entry.\"\"\"\n    if \"Severity\" not in vuln:\n        return DEFAULT_SARIF_SEVERITY\n    severity = vuln[\"Severity\"].upper()\n    return SARIF_SEVERITY_BY_OSV_SEVERITY.get(severity, DEFAULT_SARIF_SEVERITY)\ndef to_result_sarif(\n    path: str, severity: str, vuln_id: str, description: str, lineno: int\n):",
        "detail": ".trunk.plugins.trunk.linters.trivy.trivy_fs_vuln_to_sarif",
        "documentation": {}
    },
    {
        "label": "aws_access_key_id",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "description": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "peekOfCode": "aws_access_key_id = \"AKIAXYZDQCEN4EXAMPLE\"\naws_secret_access_key = \"Tg0pz8Jii8hkLx4+PnUisM8GmKs3a2DK+EXAMPLE\"\n# The below keys are copied from https://github.com/dustin-decker/secretsandstuff\ngithub_secret = \"369963c1434c377428ca8531fbc46c0c43d037a0\"\nbasic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = '''\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "documentation": {}
    },
    {
        "label": "aws_secret_access_key",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "description": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "peekOfCode": "aws_secret_access_key = \"Tg0pz8Jii8hkLx4+PnUisM8GmKs3a2DK+EXAMPLE\"\n# The below keys are copied from https://github.com/dustin-decker/secretsandstuff\ngithub_secret = \"369963c1434c377428ca8531fbc46c0c43d037a0\"\nbasic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = '''\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "documentation": {}
    },
    {
        "label": "github_secret",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "description": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "peekOfCode": "github_secret = \"369963c1434c377428ca8531fbc46c0c43d037a0\"\nbasic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = '''\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF\nOLZKbDA5aa24idpcD8b1I9/RzTOB1fu0of5xd9vgODzGw5JvHQSJ0FaA42aNBMGwrDhDB3\nsgnRNdWf6NNIh8KpXXMKJADf3klsyn6He8L2bPMp8a4wwys2YB35p5zQ0JURovsdewlOxH",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "documentation": {}
    },
    {
        "label": "basic_auth",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "description": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "peekOfCode": "basic_auth = \"https://admin:admin@the-internet.herokuapp.com/basic_auth\"\npriv_key = '''\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF\nOLZKbDA5aa24idpcD8b1I9/RzTOB1fu0of5xd9vgODzGw5JvHQSJ0FaA42aNBMGwrDhDB3\nsgnRNdWf6NNIh8KpXXMKJADf3klsyn6He8L2bPMp8a4wwys2YB35p5zQ0JURovsdewlOxH\nNT7eP19eVf4dCreibxUmRUaob5DEoHEk8WrxjKWIYUuLeD6AfcW6oXyRU2Yy8Vrt6SqFl5",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "documentation": {}
    },
    {
        "label": "priv_key",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "description": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "peekOfCode": "priv_key = '''\n-----BEGIN OPENSSH PRIVATE KEY-----\nb3BlbnNzaC1rZXktdjEAAAAACmFlczI1Ni1jdHIAAAAGYmNyeXB0AAAAGAAAABAjNIZuun\nxgLkM8KuzfmQuRAAAAEAAAAAEAAAGXAAAAB3NzaC1yc2EAAAADAQABAAABgQDe3Al0EMPz\nutVNk5DixaYrGMK56RqUoqGBinke6SWVWmqom1lBcJWzor6HlnMRPPr7YCEsJKL4IpuVwu\ninRa5kdtNTyM7yyQTSR2xXCS0fUItNuq8pUktsH8VUggpMeew8hJv7rFA7tnIg3UXCl6iF\nOLZKbDA5aa24idpcD8b1I9/RzTOB1fu0of5xd9vgODzGw5JvHQSJ0FaA42aNBMGwrDhDB3\nsgnRNdWf6NNIh8KpXXMKJADf3klsyn6He8L2bPMp8a4wwys2YB35p5zQ0JURovsdewlOxH\nNT7eP19eVf4dCreibxUmRUaob5DEoHEk8WrxjKWIYUuLeD6AfcW6oXyRU2Yy8Vrt6SqFl5\nWAi47VMFTkDZYS/eCvG53q9UBHpCj7Qvb0vSkCZXBvBIhlw193F3PX4WvO1IXsMwvQ1D1X",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.test_data.secrets.in",
        "documentation": {}
    },
    {
        "label": "to_result_sarif",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "peekOfCode": "def to_result_sarif(path: str, line_number: int, vuln_id: str, description: str):\n    return {\n        \"level\": \"error\",\n        \"locations\": [\n            {\n                \"physicalLocation\": {\n                    \"artifactLocation\": {\n                        \"uri\": path,\n                    },\n                    \"region\": {",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "documentation": {}
    },
    {
        "label": "sliding_window",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "peekOfCode": "def sliding_window(iterable, n):\n    # sliding_window('ABCDEFG', 4) --> ABCD BCDE CDEF DEFG\n    it = iter(iterable)\n    window = collections.deque(islice(it, n - 1), maxlen=n)\n    for x in it:\n        window.append(x)\n        yield tuple(window)\nsecret_lineno_cache = {}\nfile_cache = {}\ndef find_line_number(secret, path):",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "documentation": {}
    },
    {
        "label": "find_line_number",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "peekOfCode": "def find_line_number(secret, path):\n    if path not in file_cache:\n        file_cache[path] = open(path).readlines()\n    if secret not in secret_lineno_cache:\n        secret_lineno_cache[secret] = []\n    secret_length = len(secret.splitlines())\n    lines = file_cache[path]\n    for lineno, window in enumerate(sliding_window(lines, secret_length), 1):\n        # trufflehog can report the same secret multiple times\n        # if it truly appears multiple times, then we want to log different lines for each issue",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "peekOfCode": "def main(argv):\n    results = []\n    for line in sys.stdin.readlines():\n        vuln_json = json.loads(line)\n        # trufflehog doesn't have vuln IDs\n        # this is the name of the detector that found the error (e.g. AWS, Github, PrivateKey)\n        vuln_id = vuln_json[\"DetectorName\"]\n        # There also isn't description of the error aside from the raw secret, the redacted secret,\n        # and the detector that found it.\n        #",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "documentation": {}
    },
    {
        "label": "secret_lineno_cache",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "peekOfCode": "secret_lineno_cache = {}\nfile_cache = {}\ndef find_line_number(secret, path):\n    if path not in file_cache:\n        file_cache[path] = open(path).readlines()\n    if secret not in secret_lineno_cache:\n        secret_lineno_cache[secret] = []\n    secret_length = len(secret.splitlines())\n    lines = file_cache[path]\n    for lineno, window in enumerate(sliding_window(lines, secret_length), 1):",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "documentation": {}
    },
    {
        "label": "file_cache",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "description": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "peekOfCode": "file_cache = {}\ndef find_line_number(secret, path):\n    if path not in file_cache:\n        file_cache[path] = open(path).readlines()\n    if secret not in secret_lineno_cache:\n        secret_lineno_cache[secret] = []\n    secret_length = len(secret.splitlines())\n    lines = file_cache[path]\n    for lineno, window in enumerate(sliding_window(lines, secret_length), 1):\n        # trufflehog can report the same secret multiple times",
        "detail": ".trunk.plugins.trunk.linters.trufflehog.trufflehog_to_sarif",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "class A:\n    def method1(self) -> None:\n        self.x = 1\n    def method2(self) -> None:\n        self.x = \"\"\na = A()\nreveal_type(a.x)\na.x = \"\"\na.x = 3.0\nclass A:",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "class A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)\nprint(A.y)\nprint(A.z)\nclass Color(Enum):\n    RED = 1",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "Color",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "class Color(Enum):\n    RED = 1\n    BLUE = 2\ndef is_red(color: Color) -> bool:\n    if color == Color.RED:\n        return True\n    elif color == Color.BLUE:\n        return False\ndef func(val: int | None):\n    if val is not None:",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "wrong_type",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "def wrong_type(x: int) -> str:\n    return x  # error: Incompatible return value type (got \"int\", expected \"str\")\nclass A:\n    def method1(self) -> None:\n        self.x = 1\n    def method2(self) -> None:\n        self.x = \"\"\na = A()\nreveal_type(a.x)\na.x = \"\"",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "is_red",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "def is_red(color: Color) -> bool:\n    if color == Color.RED:\n        return True\n    elif color == Color.BLUE:\n        return False\ndef func(val: int | None):\n    if val is not None:\n        def inner_1() -> None:\n            reveal_type(val)\n            print(val + 1)",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "func",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "def func(val: int | None):\n    if val is not None:\n        def inner_1() -> None:\n            reveal_type(val)\n            print(val + 1)\n        inner_2 = lambda: reveal_type(val) + 1\n        inner_1()\n        inner_2()",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "a = A()\nreveal_type(a.x)\na.x = \"\"\na.x = 3.0\nclass A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "a.x",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "a.x = \"\"\na.x = 3.0\nclass A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)\nprint(A.y)\nprint(A.z)",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "a.x",
        "kind": 5,
        "importPath": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "peekOfCode": "a.x = 3.0\nclass A:\n    x: int = 0 # Regular class variable\n    y: ClassVar[int] = 0 # Pure class variable\n    def __init__(self):\n        self.z = 0 # Pure instance variable\nprint(A.x)\nprint(A.y)\nprint(A.z)\nclass Color(Enum):",
        "detail": ".trunk.plugins.trunk.linters.ty.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "NoDocstring",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "peekOfCode": "class NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1\nclass Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'\n#whitespace below vvv\n  #A malindented comment\nif __name__ == \"__main__\" :\n      a=4+1",
        "detail": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "Globe",
        "kind": 6,
        "importPath": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "peekOfCode": "class Globe(object):\n    def __init__(self):\n        self.shape = 'spheroid'\n#whitespace below vvv\n  #A malindented comment\nif __name__ == \"__main__\" :\n      a=4+1\n      b=( 2*7 )\n      c = [1,\n           2,",
        "detail": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "description": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "peekOfCode": "def main():\n    try:\n        pass\n    except (Exception, TypeError):\n        pass\nimport sys\n# trunk-ignore(flake8/F401): this will trigger a warning to verify that the config is applied\nclass NoDocstring(object):\n    def __init__(self, arg1):\n        self._attr1 = arg1",
        "detail": ".trunk.plugins.trunk.linters.yapf.test_data.basic.in",
        "documentation": {}
    },
    {
        "label": "ContextLevel",
        "kind": 6,
        "importPath": "src.dynel.dynel",
        "description": "src.dynel.dynel",
        "peekOfCode": "class ContextLevel(Enum):\n    \"\"\"Enum for specifying the level of context in log messages.\"\"\"\n    MINIMAL = 'minimal'\n    MEDIUM = 'medium'\n    DETAILED = 'detailed'\nclass CustomContext(Dict[str, Union[str, int, Dict[str, Any]]]):\n    \"\"\"Type hint for custom context data in log messages.\"\"\"\nclass DynelConfig:\n    \"\"\"Configuration class responsible for managing Dynel's logging settings.\n    Attributes:",
        "detail": "src.dynel.dynel",
        "documentation": {}
    },
    {
        "label": "CustomContext",
        "kind": 6,
        "importPath": "src.dynel.dynel",
        "description": "src.dynel.dynel",
        "peekOfCode": "class CustomContext(Dict[str, Union[str, int, Dict[str, Any]]]):\n    \"\"\"Type hint for custom context data in log messages.\"\"\"\nclass DynelConfig:\n    \"\"\"Configuration class responsible for managing Dynel's logging settings.\n    Attributes:\n        CONTEXT_LEVEL_MAP (dict): Maps context level strings to ContextLevel Enum.\n        CUSTOM_CONTEXT_LEVEL (ContextLevel): Specifies the context level.\n        DEBUG_MODE (bool): Indicates if the logger is in debug mode.\n        FORMATTING_ENABLED (bool): Indicates if special formatting is enabled.\n        EXCEPTION_CONFIG (dict): Maps function names to their exception-handling configurations.",
        "detail": "src.dynel.dynel",
        "documentation": {}
    },
    {
        "label": "DynelConfig",
        "kind": 6,
        "importPath": "src.dynel.dynel",
        "description": "src.dynel.dynel",
        "peekOfCode": "class DynelConfig:\n    \"\"\"Configuration class responsible for managing Dynel's logging settings.\n    Attributes:\n        CONTEXT_LEVEL_MAP (dict): Maps context level strings to ContextLevel Enum.\n        CUSTOM_CONTEXT_LEVEL (ContextLevel): Specifies the context level.\n        DEBUG_MODE (bool): Indicates if the logger is in debug mode.\n        FORMATTING_ENABLED (bool): Indicates if special formatting is enabled.\n        EXCEPTION_CONFIG (dict): Maps function names to their exception-handling configurations.\n    \"\"\"\n    def __init__(self, context_level: str = 'min', debug: bool = False, formatting: bool = True, panic_mode: bool = False):",
        "detail": "src.dynel.dynel",
        "documentation": {}
    },
    {
        "label": "configure_logging",
        "kind": 2,
        "importPath": "src.dynel.dynel",
        "description": "src.dynel.dynel",
        "peekOfCode": "def configure_logging(config: DynelConfig) -> None:\n    \"\"\"Configure logging settings based on DynelConfig.\n    Args:\n        config (DynelConfig): Configuration object.\n    \"\"\"\n    log_format = \"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>\"\n    logger.remove()\n    logger.add(\n        sink=\"dynel.log\",\n        level=\"DEBUG\" if config.DEBUG_MODE else \"INFO\",",
        "detail": "src.dynel.dynel",
        "documentation": {}
    },
    {
        "label": "global_exception_handler",
        "kind": 2,
        "importPath": "src.dynel.dynel",
        "description": "src.dynel.dynel",
        "peekOfCode": "def global_exception_handler(config: DynelConfig, message: str) -> None:\n    \"\"\"Global exception handler.\n    Args:\n        config (DynelConfig): Configuration object.\n        message (str): Exception message.\n    \"\"\"\n    logger.exception(\"An unhandled exception has occurred: {}\", message)\ndef handle_exception(config: DynelConfig, error: Union[Exception, Callable]) -> None:\n    \"\"\"Handles exceptions based on function-specific expected exceptions.\n    Args:",
        "detail": "src.dynel.dynel",
        "documentation": {}
    },
    {
        "label": "handle_exception",
        "kind": 2,
        "importPath": "src.dynel.dynel",
        "description": "src.dynel.dynel",
        "peekOfCode": "def handle_exception(config: DynelConfig, error: Union[Exception, Callable]) -> None:\n    \"\"\"Handles exceptions based on function-specific expected exceptions.\n    Args:\n        config (DynelConfig): Configuration object.\n        error (Union[Exception, Callable]): The exception or callable that raised the exception.\n    \"\"\"\n    func_name = inspect.stack()[1][3]\n    function_config = config.EXCEPTION_CONFIG.get(func_name, {})\n    context_level = config.CUSTOM_CONTEXT_LEVEL\n    frame = inspect.currentframe()",
        "detail": "src.dynel.dynel",
        "documentation": {}
    },
    {
        "label": "module_exception_handler",
        "kind": 2,
        "importPath": "src.dynel.dynel",
        "description": "src.dynel.dynel",
        "peekOfCode": "def module_exception_handler(config: DynelConfig, module: Any) -> None:\n    \"\"\"Attaches exception handlers to module functions.\n    Args:\n        config (DynelConfig): Configuration object.\n        module (Any): The module to attach exception handlers to.\n    \"\"\"\n    for name, obj in inspect.getmembers(module):\n        if inspect.isfunction(obj):\n            def _onerror_handler(exc_or_result):\n                if isinstance(exc_or_result, Exception):",
        "detail": "src.dynel.dynel",
        "documentation": {}
    },
    {
        "label": "parse_command_line_args",
        "kind": 2,
        "importPath": "src.dynel.dynel",
        "description": "src.dynel.dynel",
        "peekOfCode": "def parse_command_line_args() -> Dict[str, Any]:\n    \"\"\"Parses command-line arguments and returns them as a dictionary.\n    Returns:\n        Dict[str, Any]: Dictionary of parsed command-line arguments.\n    \"\"\"\n    parser = argparse.ArgumentParser(description='Error Logging Configuration')\n    parser.add_argument('--context-level', type=str, choices=['min', 'minimal', 'med', 'medium', 'det', 'detailed'], default='min', help='Set context level for error logging')\n    parser.add_argument('--debug', action='store_true', default=False, dest='debug', help='Run the program in debug mode')\n    parser.add_argument('--no-formatting', action='store_false', default=True, dest='formatting', help='Disable special formatting')\n    args = parser.parse_args()",
        "detail": "src.dynel.dynel",
        "documentation": {}
    },
    {
        "label": "SomeClass",
        "kind": 6,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "class SomeClass: # Should not be wrapped\n    def method(self):\n        raise AttributeError(\"Dummy AttributeError in class\")\n\"\"\"\n@pytest.fixture\ndef dummy_module(tmp_path):\n    \"\"\"Creates a dummy module file and imports it.\"\"\"\n    module_path = tmp_path / \"dummy_module_for_dynel_test.py\"\n    module_path.write_text(DUMMY_MODULE_CONTENT)\n    import importlib.util",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "temp_config_file_generator",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def temp_config_file_generator(): # Removed tmp_path from fixture signature\n    \"\"\"\n    Factory fixture to generate temporary config files (json, yaml, toml).\n    The actual tmp_path should be passed by the test function.\n    \"\"\"\n    def _create_temp_file(base_path: Path, filename_prefix: str, extension: str, data: dict): # Added base_path\n        file_path = base_path / f\"{filename_prefix}.{extension}\"\n        if extension == \"json\":\n            with open(file_path, \"w\") as f:\n                json.dump(data, f)",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "dynel_config_instance",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def dynel_config_instance():\n    \"\"\"Returns a default DynelConfig instance.\"\"\"\n    return DynelConfig()\n# --- Tests for DynelConfig ---\ndef test_dynel_config_defaults(dynel_config_instance):\n    assert dynel_config_instance.CUSTOM_CONTEXT_LEVEL == ContextLevel.MINIMAL\n    assert dynel_config_instance.DEBUG_MODE is False\n    assert dynel_config_instance.FORMATTING_ENABLED is True\n    assert dynel_config_instance.PANIC_MODE is False\n    assert dynel_config_instance.EXCEPTION_CONFIG == {}",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_dynel_config_defaults",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_dynel_config_defaults(dynel_config_instance):\n    assert dynel_config_instance.CUSTOM_CONTEXT_LEVEL == ContextLevel.MINIMAL\n    assert dynel_config_instance.DEBUG_MODE is False\n    assert dynel_config_instance.FORMATTING_ENABLED is True\n    assert dynel_config_instance.PANIC_MODE is False\n    assert dynel_config_instance.EXCEPTION_CONFIG == {}\n@pytest.mark.parametrize(\"ext\", [\"json\", \"yaml\", \"toml\"])\ndef test_load_exception_config_valid(temp_config_file_generator, dynel_config_instance, ext, tmp_path, monkeypatch): # Added monkeypatch\n    config_data = VALID_CONFIG_DATA_DICT.copy()\n    filename_prefix = \"test_dynel_config\"",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_load_exception_config_valid",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_load_exception_config_valid(temp_config_file_generator, dynel_config_instance, ext, tmp_path, monkeypatch): # Added monkeypatch\n    config_data = VALID_CONFIG_DATA_DICT.copy()\n    filename_prefix = \"test_dynel_config\"\n    temp_config_file_generator(tmp_path, filename_prefix, ext, config_data) # Pass tmp_path from test\n    # Temporarily change CWD to where the temp file is, or pass full path\n    # The temp_config_file_generator fixture has already used tmp_path to create the file.\n    # We need tmp_path directly in the test to patch Path.cwd.\n    # The fixture `temp_config_file_generator` returns the function `_create_temp_file`\n    # The actual tmp_path is available via the `tmp_path` fixture injected into the test.\n    # So, the patch should use the `tmp_path` fixture available in the test's scope.",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_load_exception_config_file_not_found",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_load_exception_config_file_not_found(dynel_config_instance):\n    with pytest.raises(FileNotFoundError):\n        dynel_config_instance.load_exception_config(\"non_existent_config\")\n@pytest.mark.parametrize(\"ext\", [\"json\", \"yaml\", \"toml\"])\ndef test_load_exception_config_invalid_format(dynel_config_instance, ext, tmp_path, monkeypatch): # Added monkeypatch\n    filename_prefix = \"invalid_config\"\n    file_path = tmp_path / f\"{filename_prefix}.{ext}\"\n    with open(file_path, \"w\") as f:\n        f.write(\"this is not valid {syntax,, for all formats\") # Write an invalid string\n    monkeypatch.chdir(tmp_path) # Use monkeypatch to change CWD",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_load_exception_config_invalid_format",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_load_exception_config_invalid_format(dynel_config_instance, ext, tmp_path, monkeypatch): # Added monkeypatch\n    filename_prefix = \"invalid_config\"\n    file_path = tmp_path / f\"{filename_prefix}.{ext}\"\n    with open(file_path, \"w\") as f:\n        f.write(\"this is not valid {syntax,, for all formats\") # Write an invalid string\n    monkeypatch.chdir(tmp_path) # Use monkeypatch to change CWD\n    if ext == \"yaml\":\n        # For YAML, a plain string is valid YAML, so it won't be a parsing error,\n        # but rather a type error because the root is not a dict.\n        with pytest.raises(ValueError, match=r\"Invalid DynEL configuration file .* Root of configuration must be a dictionary.\"):",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_load_exception_config_safer_exception_loading",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_load_exception_config_safer_exception_loading(temp_config_file_generator, dynel_config_instance, ext, tmp_path, monkeypatch): # Added monkeypatch\n    \"\"\"Tests the safer loading of exception types (built-in, importable, and invalid).\"\"\"\n    config_data = {\n        \"debug_mode\": False,\n        \"FuncWithBuiltin\": {\"exceptions\": [\"ValueError\", \"DoesNotExist\"]}, # DoesNotExist is not std builtin\n        \"FuncWithImportable\": {\"exceptions\": [\"os.PathLike\"]}, # os.PathLike is not an exception\n        \"FuncWithNonException\": {\"exceptions\": [\"src.dynel.ContextLevel\"]}, # Valid class, not an exception\n        \"FuncWithUnresolvable\": {\"exceptions\": [\"nonexistent_module.NonExistentError\"]},\n    }\n    filename_prefix = \"test_exc_loading\"",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_configure_logging_debug_mode",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_configure_logging_debug_mode(mock_loguru_logger, dynel_config_instance):\n    dynel_config_instance.DEBUG_MODE = True\n    configure_logging(dynel_config_instance)\n    mock_loguru_logger.remove.assert_called_once()\n    # Check that logger.add was called for dynel.log with DEBUG level\n    # This is a bit complex due to multiple calls to .add()\n    # We can inspect call_args_list\n    args_list = mock_loguru_logger.add.call_args_list\n    assert any(\n        call[1].get('sink') == 'dynel.log' and call[1].get('level') == 'DEBUG'",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_configure_logging_production_mode",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_configure_logging_production_mode(mock_loguru_logger, dynel_config_instance):\n    dynel_config_instance.DEBUG_MODE = False\n    configure_logging(dynel_config_instance)\n    mock_loguru_logger.remove.assert_called_once()\n    args_list = mock_loguru_logger.add.call_args_list\n    assert any(\n        call[1].get('sink') == 'dynel.log' and call[1].get('level') == 'INFO'\n        for call in args_list\n    )\n# --- Tests for parse_command_line_args ---",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_parse_command_line_args_defaults",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_parse_command_line_args_defaults():\n    with patch('argparse.ArgumentParser.parse_args', return_value=Mock(context_level='min', debug=False, formatting=True)):\n        args = parse_command_line_args()\n    assert args['context_level'] == 'min'\n    assert args['debug'] is False\n    assert args['formatting'] is True\n@pytest.mark.parametrize(\"cli_arg, expected_key, expected_value, context_choices\", [\n    (['--context-level', 'med'], 'context_level', 'med', ['min', 'med', 'det']),\n    (['--debug'], 'debug', True, None),\n    (['--no-formatting'], 'formatting', False, None)",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_parse_command_line_args_custom",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_parse_command_line_args_custom(cli_arg, expected_key, expected_value, context_choices):\n    # The choices for context_level are defined in the function, so we don't need to pass them all here\n    # just ensuring the mechanism works\n    with patch('sys.argv', ['dynel.py'] + cli_arg):\n         parsed_args = parse_command_line_args()\n    assert parsed_args[expected_key] == expected_value\n# --- Tests for handle_exception ---\n@pytest.fixture\ndef captured_logs():\n    \"\"\"Fixture to capture Loguru logs in a list.\"\"\"",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "captured_logs",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def captured_logs():\n    \"\"\"Fixture to capture Loguru logs in a list.\"\"\"\n    log_capture_list = []\n    def capturing_sink(message):\n        log_capture_list.append(message.record) # Store the full record for detailed assertions\n    # Ensure default logger is clean and add our sink\n    # Note: This might interfere if other tests also manipulate the global logger.\n    # For isolated tests, this is okay. Consider per-test logger configuration if issues arise.\n    from src.dynel.dynel import logger as dynel_logger # get the actual logger instance\n    dynel_logger.remove() # Remove all handlers",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_handle_exception_basic_logging",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_handle_exception_basic_logging(dynel_config_instance, captured_logs):\n    config = dynel_config_instance\n    error_to_raise = ValueError(\"Test error for basic logging\")\n    # Mock inspect.stack() to control func_name\n    with patch('inspect.stack') as mock_stack:\n        mock_function_name = \"mock_function_raising_error\"\n        # inspect.stack()[1] should be a tuple/list where index 3 is the function name\n        mock_caller_frame_tuple = (Mock(), \"filename_mock\", 123, mock_function_name, [\"code_line_mock\"], 0)\n        mock_stack.return_value = [\n            Mock(), # Frame for handle_exception itself",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_handle_exception_with_custom_message_and_tags",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_handle_exception_with_custom_message_and_tags(dynel_config_instance, captured_logs):\n    config = dynel_config_instance\n    func_name = \"my_specific_function\"\n    custom_msg = \"A very specific error occurred!\"\n    tags = [\"database\", \"critical\"]\n    config.EXCEPTION_CONFIG = {\n        func_name: {\n            \"exceptions\": [TypeError],\n            \"custom_message\": custom_msg,\n            \"tags\": tags",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_handle_exception_context_levels",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_handle_exception_context_levels(level_str, expected_keys_in_extra, captured_logs):\n    # For 'det' level, mock os.environ to avoid logging actual environment\n    mock_os_environ = {\"TEST_VAR\": \"test_value\"}\n    with patch('os.environ', mock_os_environ), \\\n         patch('src.dynel.dynel.inspect') as mock_dynel_inspect: # Patch inspect used in dynel.py\n        config = DynelConfig(context_level=level_str)\n        mock_function_name = \"context_level_test_func\"\n        # Setup for inspect.stack()[1][3] to get mock_function_name\n        mock_caller_frame_tuple = (Mock(), \"filename_mock\", 123, mock_function_name, [\"code_line_mock\"], 0)\n        mock_dynel_inspect.stack.return_value = [",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_handle_exception_panic_mode",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_handle_exception_panic_mode(dynel_config_instance, captured_logs):\n    config = dynel_config_instance\n    config.PANIC_MODE = True\n    error_to_raise = RuntimeError(\"Critical system failure!\")\n    func_name = \"panicking_function\"\n    with patch('inspect.stack') as mock_stack, \\\n         patch('sys.exit') as mock_sys_exit: # Patch sys.exit\n        # inspect.stack()[1] should be a tuple/list where index 3 is the function name\n        mock_caller_frame_tuple = (Mock(), \"filename_mock\", 123, func_name, [\"code_line_mock\"], 0)\n        mock_stack.return_value = [",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "func_that_works",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def func_that_works():\n    return \"worked\"\ndef func_that_raises_value_error():\n    raise ValueError(\"Dummy ValueError\")\ndef func_that_raises_type_error():\n    raise TypeError(\"Dummy TypeError\")\n_a_private_variable = True # Should not be wrapped\nclass SomeClass: # Should not be wrapped\n    def method(self):\n        raise AttributeError(\"Dummy AttributeError in class\")",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "func_that_raises_value_error",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def func_that_raises_value_error():\n    raise ValueError(\"Dummy ValueError\")\ndef func_that_raises_type_error():\n    raise TypeError(\"Dummy TypeError\")\n_a_private_variable = True # Should not be wrapped\nclass SomeClass: # Should not be wrapped\n    def method(self):\n        raise AttributeError(\"Dummy AttributeError in class\")\n\"\"\"\n@pytest.fixture",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "func_that_raises_type_error",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def func_that_raises_type_error():\n    raise TypeError(\"Dummy TypeError\")\n_a_private_variable = True # Should not be wrapped\nclass SomeClass: # Should not be wrapped\n    def method(self):\n        raise AttributeError(\"Dummy AttributeError in class\")\n\"\"\"\n@pytest.fixture\ndef dummy_module(tmp_path):\n    \"\"\"Creates a dummy module file and imports it.\"\"\"",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "dummy_module",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def dummy_module(tmp_path):\n    \"\"\"Creates a dummy module file and imports it.\"\"\"\n    module_path = tmp_path / \"dummy_module_for_dynel_test.py\"\n    module_path.write_text(DUMMY_MODULE_CONTENT)\n    import importlib.util\n    spec = importlib.util.spec_from_file_location(\"dummy_module_for_dynel_test\", module_path)\n    imported_module = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(imported_module)\n    return imported_module\ndef test_module_exception_handler_wraps_functions(dynel_config_instance, dummy_module):",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_module_exception_handler_wraps_functions",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_module_exception_handler_wraps_functions(dynel_config_instance, dummy_module):\n    config = dynel_config_instance\n    # Keep a reference to original functions to reset if necessary, though for this test structure,\n    # the dummy_module is fresh each time due to fixture scope.\n    # original_value_error_func = dummy_module.func_that_raises_value_error\n    # original_works_func = dummy_module.func_that_works\n    with patch('src.dynel.dynel.handle_exception') as mock_handle_exception:\n        mock_handle_exception.return_value = None # Ensure mock doesn't suppress re-raise\n        module_exception_handler(config, dummy_module) # Corrected: Call module_exception_handler\n        # Test that wrapped function still works if no error",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "test_log_file_output_formats",
        "kind": 2,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "def test_log_file_output_formats(tmp_path, monkeypatch):\n    config = DynelConfig(context_level=\"med\") # Use medium context for some local_vars\n    # Configure logging to use temporary files\n    log_file_txt = tmp_path / \"output.log\"\n    log_file_json = tmp_path / \"output.json\"\n    # Patch the logger.add calls within configure_logging to use these temp files\n    # This is a bit more involved as configure_logging removes all handlers then adds new ones.\n    # We can patch 'logger.add' and inspect its calls, or patch the sink names directly if possible.\n    # A simpler way for this test: modify the configure_logging function temporarily for the test,\n    # or have DynelConfig allow specifying log paths.",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "VALID_CONFIG_DATA_DICT",
        "kind": 5,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "VALID_CONFIG_DATA_DICT = {\n    \"debug_mode\": True,\n    \"MyFunction\": {\n        \"exceptions\": [\"ValueError\", \"TypeError\"],\n        \"custom_message\": \"Custom error in MyFunction\",\n        \"tags\": [\"critical\", \"data_processing\"]\n    },\n    \"AnotherFunction\": {\n        \"exceptions\": [\"KeyError\"],\n        \"custom_message\": \"Key not found\",",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "DUMMY_MODULE_CONTENT",
        "kind": 5,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "DUMMY_MODULE_CONTENT = \"\"\"\ndef func_that_works():\n    return \"worked\"\ndef func_that_raises_value_error():\n    raise ValueError(\"Dummy ValueError\")\ndef func_that_raises_type_error():\n    raise TypeError(\"Dummy TypeError\")\n_a_private_variable = True # Should not be wrapped\nclass SomeClass: # Should not be wrapped\n    def method(self):",
        "detail": "tests.test_dynel",
        "documentation": {}
    },
    {
        "label": "_a_private_variable",
        "kind": 5,
        "importPath": "tests.test_dynel",
        "description": "tests.test_dynel",
        "peekOfCode": "_a_private_variable = True # Should not be wrapped\nclass SomeClass: # Should not be wrapped\n    def method(self):\n        raise AttributeError(\"Dummy AttributeError in class\")\n\"\"\"\n@pytest.fixture\ndef dummy_module(tmp_path):\n    \"\"\"Creates a dummy module file and imports it.\"\"\"\n    module_path = tmp_path / \"dummy_module_for_dynel_test.py\"\n    module_path.write_text(DUMMY_MODULE_CONTENT)",
        "detail": "tests.test_dynel",
        "documentation": {}
    }
]